\chapter{Métodos estadísticos para la búsqueda de nueva física}

En este capítulo se introducen los conceptos básicos necesarios para entender el
tratamiento estadístico de los datos. Esta enfocado en la búsqueda de nueva
física en altas energías, su descubrimiento y/o el establecimiento de límites de
exclusión.

Dada la naturaleza probabilística de las colisiones en el LHC y el bajo número
de eventos esperados en las búsquedas de nueva física, es necesario contar con
un poderoso marco estadístico para interpretar los resultados, especialmente
para identificar una nueva señal sobre las posibles fluctuaciones de los fondos
del SM.


\section{Funciones de distribución de probabilidad}

Un observable $x$ es por naturaleza \emph{frecuentista}, es decir, si realizamos
el experimento muchas veces, vamos a obtener distintos valores para $x$ y este
conjunto de valores va a dar lugar a una función densidad de probabilidad (pdf)
de $x$, que llamamos $f(x)$. En el caso más general, se cuenta con una familia
de pdfs $f(x;\btheta)$ a la cual se denomina \emph{modelo}. Los parámetros del
modelo representan, por ejemplo, parámetros de la teoría física, alguna
propiedad desconocida de la respuesta del detector, o incertezas sistemáticas
del análisis.

A continuación se describen algunas funciones de probabilidad importantes que
serán utilizadas a lo largo de este Capítulo.

\subsubsection{Distribución Gaussiana}

La pdf Gaussiana (o normal) de una variable continua $x$ ($-\infty < x < \infty$)
se define como:

\begin{equation}
  f(x;\mu,\sigma) = \frac{1}{\sqrt{2\pi \sigma^2}} \exp \left( \frac{-(x-\mu)^2}{2\sigma^2} \right)
\end{equation}

Los nombres de los parámetros están claramente motivados por los valores del valor
esperado y la varianza de $x$, ya que $E[x] = \mu$ y $V[x] = \sigma^2$. Un caso especial
es cuando $\mu=0$ y $\sigma=1$, la cual se denomina Gaussiana Estándar.
%% $\phi(x) = \frac{1}{\sqrt{2\pi}} \exp(-x^2/2)$.
La importancia de la distribución normal proviene del Teorema Central del Limite.
El teorema dice que la suma de $n$ variables continuas independientes $x_i$ con media $\mu_i$
y varianza $\sigma_i^2$ esta distribuida de acuerdo a una Gaussiana con media $\mu = \sum_{i=1}^n \mu_i$
y varianza $\sigma^2 = \sum_{i=1}^n \sigma_i^2$ en el limite de $n\to\infty$. Esto es así (bajo
ciertas condiciones generales) sin importar las pdfs individuales de $x_i$.


\subsubsection{Distribución $\chi^2$}

La distribución $\chi^2$ de una variable continua $z$ ($0 \leq z \leq \infty$) se
define como:

\begin{equation}
  f(z;n) = \frac{1}{2^{n/2}\Gamma(n/2)} z^{n/2-1} e^{-z/2}, \quad n=1,2,\ldots
\end{equation}
%
donde $n$ es llamado el número de grados de libertad.
Dadas $N$ variables $x_i$ gaussianas con media $\mu_i$ y $\sigma_i^2$, la
variable $z = \sum_{i=1}^{N} \frac{(x_i-\mu_i)^2}{\sigma_i^2}$ esta distribuida
de acuerdo a una distribución $\chi^2$ con $N$ grados de libertad.


\subsubsection{Distribución de Poisson}

La distribución de Poisson es una distribución de probabilidad discreta que
describe, a partir de una frecuencia de ocurrencia media, la probabilidad de que
ocurra un determinado número de eventos durante cierto período de tiempo. Un
ejemplo típico que puede ser descripto por esta distribución es el número de
clicks de un contador Geiger en un determinado intervalo de tiempo.

Se la puede pensar como un límite de la distribución binomial cuando el número ($N$)
de experimentos tiende a infinito y la probabilidad ($p$) a cero, pero el producto es
constantes $Np = \nu$. En ese caso la función de probabilidad esta dada por:

\begin{equation}
  \Pois(n;\nu) = \frac{\nu^n}{n!} e^{-\nu}
\end{equation}

Su valor esperado es $E[n] = \nu$ y la varianza $V[n] = \nu$.
Cuando $\nu \to \infty$ la distribución de Poisson converge a una distribución
normal de media $\nu$ y ancho $\sqrt{\nu}$.


\section{Estimadores}

La estimación de parámetros de las distribuciones observadas es una de las
tareas fundamentales del análisis de datos, y puede considerarse como la
medición de un parámetro (que tiene un valor fijo pero desconocido) basado en un
número limitado de observaciones experimentales. Dado el experimento, la
estimación puntual consiste en determinar un valor único lo mas cerca posible al
valor verdadero.

Supongamos un conjunto de $N$ observaciones $\bm{x} = (x_1, x_2, \ldots, x_N)$,
donde las medidas $x_i$ son estadísticamente independientes y cada una está
descripta por una función de densidad de probabilidad $f(x;\btheta)$ que no
conocemos, donde $\btheta$ es un conjunto de parámetros con valores
desconocidos, que tienen un valor verdadero $\btheta_0$.

Un \emph{estimador} es una función de los datos observados $\bm{x}$ que provee
valores numéricos, los valores estimados $\hat{\btheta}$, para el vector de
parámetros $\btheta$.

Algunas propiedades que es importante que cumplan los estimadores son:

\begin{itemize}\itemsep0.2cm\parskip0.2cm
\item {\bf Consistencia:} Un estimador se dice consistente (o asintóticamente
  consistente) si converge al valor verdadero $\btheta_{0}$ con el número de
  medidas $N$: $\lim_{N \to \infty} \hat{\btheta} = \btheta_0$.

\item {\bf Sesgo:} El sesgo esta definido como la diferencia entre el valor
  esperado del estimador y el valor verdadero: $E[\hat{\btheta}] - \btheta_0$ y
  un estimador es no sesgado cuando el sesgo es cero.

\item {\bf Eficiencia:} Un estimador es eficiente si su varianza
  $V[\hat{\btheta}]$ es chica.
\end{itemize}

Los dos métodos mas utilizados para la estimación de parámetros son el de
\emph{likelihood máximo} y el de \emph{mínimos cuadrados}.


\section{Método del likelihood máximo}\label{sec:MLE}

Para $N$ mediciones estadísticamente independientes cada una descripta por una
pdf $f(x, \btheta)$, la pdf conjunta para los valores observados $x$ esta dada
por $f(\bm{x}, \btheta) = \prod_i f(x_i, \btheta)$. La función \emph{likelihood}
se define como la pdf conjunta evaluada en los datos observados,

\begin{equation}
  L(\btheta) = f((x_1, x_2, \ldots, x_n); \btheta) = \prod_{i=1}^{N} f(x_i;
  \btheta)
\end{equation}

Cuando se repite un experimento con las mismas condiciones muchas veces, el
número de eventos $n$ de un proceso fluctúa de acuerdo a una distribución
de Poisson alrededor del valor esperado $\nu$. Este término de Poisson puede
incorporarse entonces a la función likelihood, obteniendo lo que se llama
\emph{likelihood extendido}:

\begin{equation}
  L(\nu,\btheta) = \Pois(n;\nu) \prod_{i=1}^{N} f(x_i; \btheta)
\end{equation}


El estimador de máximo likelihood (MLE) de los parámetros {\btheta} son los
valores $\hat{\btheta}$ para los cuales la función likelihood $L(\btheta)$ tiene
su máximo global. %% Una forma intuitiva de ver esto es la siguiente: si asumimos
%% que la pdf y los parámetros son correctos, esperamos valores altos de la función
%% likelihood comparado con otros parámetros que no sean los verdaderos.
%% Los valores estimados $\hat{\btheta}$ de los parámetros se obtienen buscando el
%% máximo global de la función likelihood.
En la práctica, es conveniente trabajar con el logaritmo de la función
likelihood (log-likelihood), y buscar el mínimo del negativo de esta función:

\begin{equation}
  - \ln L(\btheta) = - \sum_{i=1}^{N} \ln f(x_i; \btheta)
\end{equation}

En el límite asintótico, cuando el número de mediciones $N$ tiende a infinito,
el MLE es consistente, es decir, para cada parámetro $\theta$ el valor estimado
$\hat{\theta}$ converge al valor verdadero $\theta_0$. En este límite también el
MLE es no sesgado y tiene su menor varianza. Esto significa que ningún otro
estimador puede ser más eficiente. Para un número finito de eventos $N$, sin
embargo, el MLE tiene un sesgo proporcional a $1/N$.


\section{Contrastación de hipótesis}
\label{sec:testhypo}

En las secciones anteriores se describió cómo pueden utilizarse los datos observados
para estimar parámetros. En esta sección se describirá cómo estos datos
experimentales también pueden ser usados para contrastar hipótesis, es decir,
para verificar o rechazar una teoría o hipótesis, o también para elegir entre
hipótesis alternativas. Cuando la hipótesis a contrastar involucra el valor de
un parámetro, estos dos temas están relacionados.

En general, se llama hipótesis nula ($H_0$) a la hipótesis sujeta a la prueba y
usualmente corresponde a la hipótesis que consideramos verdadera. Esta hipótesis
es comparada contra una hipótesis alternativa $H_1$, o varias, distintas a $H_0$.

En el caso de búsqueda de nueva física, la hipótesis que juega el rol de
hipótesis nula es la hipótesis de que solo los procesos del SM contribuyen a los
datos observados. Esta hipótesis también suele llamarse hipótesis de
\emph{solo-fondo}. Y la hipótesis alternativa es la hipótesis en la cual, además
de los procesos del SM, también contribuyen procesos de nueva física y se
denomina hipótesis de \emph{se\~nal+fondo}.

Una hipótesis se dice \emph{simple} cuando está completamente determinada. En
cambio, cuando tiene uno o más parámetros libres, se dice \emph{compuesta}. Cada
hipótesis queda determinada por la pdf que describe a los observables bajo esa
hipótesis $f(\bm{x}|H)$.

Una vez definidas las hipótesis, se quiere saber si los datos medidos son
compatibles con la hipótesis nula o si la hipótesis nula puede ser rechazada en
base a estos datos. Con este objetivo se define un \emph{estadístico de prueba}
$t(\bm{x})$ que es función de los datos observados. En el caso de considerar un
estadístico de prueba escalar, $t(\bm{x}) \to \mathbb{R}$, éste contendrá toda la
información de discriminación entre $H_0$ y $H_1$ en un solo número.

Cada estadístico de prueba tendrá su pdf asociada $g(t|H)$ y la decisión sobre
la hipótesis estará basada en el valor del estadístico observado $t_\text{obs}$
y la definición de una \emph{región critica} $R$. La región critica queda
definida por un valor de corte $t_c$ y para el caso de que la hipótesis
alternativa tiende a tener valores de $t$ mayores que bajo $H_0$, la región
critica corresponde a $t \geq t_c$ (ver \cref{fig:stat_test}).

Si el valor observado se encuentra fuera de la región critica (dentro de la
región de aceptancia) la hipótesis $H_0$ no puede ser rechazada, y si esta
dentro es rechazada.

\begin{figure}[h]
  \centering
  \input{tikz/stat_test.tex}
  \caption{Funciones de densidad de probabilidad para el estadístico de prueba
    $t$ bajo la hipótesis nula $H_0$ (azul) y la hipótesis alternativa $H_1$
    (rojo). Las regiones de aceptancia y rechazo quedan definidas por $t_c$.}
  \label{fig:stat_test}
\end{figure}

%% Asumiendo que $H_0$ es verdadera, se puede definir una región critica $R$ tal que la probabilidad
%% de que $q$ pertenezca a $R$ sea igual o menor a un cierto valor. El hecho de que $q_\text{obs}$
%% este dentro de $R$, implica que $H_0$ sea rechazada, y de lo contrario aceptada.

%% Primero se define una \emph{región de aceptancia}, tal que si $T(\mathcal{d}) < k_\alpha$
%% uno acepta la hipótesis nula. El contorno $T(\mathcal{d}) = k_\alpha$ delimita el espacio de datos,
%% y es el borde de la región de aceptancia. Se define el tamaño del test, $\alpha$, como la
%% probabilidad de que la hipótesis nula sea rechazada en el caso de ser verdadera (lo que se conoce
%% como error de tipo I). Esto es equivalente a la probabilidad bajo la hipótesis nula de que los datos
%% no sean encontrados en la región de aceptancia, es decir, $\alpha = P(T(\mathcal{D}) \geq k_\alpha|H_0)$

%% En contraste, si uno acepta la hipótesis nula cuando la alternativa es verdadera, es llamado
%% error de tipo II. La probabilidad de cometer este errores la denota $\beta$ y esta dada por
%% $\beta = P(T(\mathcal{D}) < k_\alpha|H_1)$. Se llama \emph{poder del test} a $1-\beta$.

%% Lo que se quiere encontrar es un test estadístico que maximiza el poder del test para un valor
%% fijo de tamaño del test $\alpha$.

La probabilidad de rechazar $H_0$ siendo ésta verdadera es denominado tamaño del test $\alpha$:

\begin{equation}
  \alpha = \int_{R} g(t|H_0)\, dt
\end{equation}
%
lo cual también determina el nivel de significancia como
$(100 - \alpha) \%$. Este error, de rechazar $H_0$ cuando la hipotesis es verdadera, es llamado
error de tipo I. Por otro lado el error de aceptar $H_0$ cuando es falsa se
llama error de tipo II, y su probabilidad de ocurrencia, $\beta$, depende de la
hipótesis alternativa $H_1$ y del poder del test que se define como $(1-\beta)$:

\begin{equation}
1-\beta = \int_R g(t|H_1)\, dt
\end{equation}

En principio cualquier función de los datos puede ser utilizada como estadístico
de prueba, pero un buen estadístico será aquel para el cual sus distribuciones
para la hipótesis nula y alternativa estén claramente separadas. Para esto se
busca el estadístico de prueba que tenga el mayor poder posible $(1-\beta)$, para un dado
tama\~no $\alpha$.

Para el caso de hipótesis simples, el teorema de Neyman-Pearson[] afirma que el
estadístico de prueba con mayor poder para un tama\~no esta dado por:

%% Para el caso de dos hipótesis simples (sin parámetros), el test estadístico con mayor
%% poder esta dado por el \emph{likelihood ratio} $T_\text{NP} = \vec{f}(\mathcal{D}|H_1)/\vec{f}(\mathcal{D}|H_0)$.
%% Este resultado se conoce como lema de Neyman-Pearson.

\begin{equation}
  t(\bm{x}) = \frac{f(\bm{x}|H_1)}{f(\bm{x}|H_0)}
\end{equation}
%
y la mejor region critica consiste en los $\bm{x}$ que satisface $t(\bm{x}) > c_\alpha$
donde $c_\alpha$ es una constante que se ajusta para que el tama\~no sea $\alpha$.
Este estadistico de prueba es esencialmente el cociente de los likelihoods
para las dos hipotesis.


El nivel de acuerdo entre los datos observados y una hipótesis $H$ es
cuantificado calculando el \emph{\pvalue}, es decir, la probabilidad, bajo la
suposición de que $H$ es cierta, de observar datos de igual o menor
compatibilidad con la predicción de $H$, respecto a los datos observados.

\begin{equation}
  p_H = P(t>t_\text{obs}|H) = \int_{t_\text{obs}}^{\infty} g(t|H) \, dt
\end{equation}
%
donde $t_\text{obs}$ es el valor del estadístico de prueba obtenido con los
datos observados.

De esta forma, un {\pvalue} grande denota que la evidencia en contra de $H_0$ es
débil y un {\pvalue} chico denota que los datos contienen mucha evidencia en
contra de $H_0$.
%% En este sentido de p-valores, se puede no hablar de pruebas de hip´otesis, sino de
%% pruebas de significancia, donde la cuantificaci´on del concepto abstracto de significancia
%% es el p-valor
Se dice que la hipótesis es excluida si el {\pvalue} se encuentra por debajo de un valor
especifico dado por el tama\~no del test $\alpha$, donde $\alpha \in [0,1]$.

En física de partículas es usual convertir el {\pvalue} en la signifícancia
equivalente, $Z$, definida de forma tal que una variable distribuida normalmente
tenga una probabilidad igual a ese {\pvalue} de ser encontrada a mas de $Z$
desviaciones estándar a la derecha de su media\footnote{Explicar que existen dos
  formas de definir. one-sided...}. Esto es:

\begin{equation}
  Z = \Phi^{-1}(1-p)
\end{equation}
%
donde $\Phi^{-1}$ es el cuantil (la función inversa de la distribución
acumulativa) de la distribución gaussiana.

Tambien es util definir, para poder cuantificar la sensibilidad de un experimento,
la significancia esperada que se obtendria dados los datos observados bajo la
supocision de ciertas hipotesis.
Para esto se calcula la significancia de la hipotesis $H_0$, respecto
a la mediana de la hipotesis $H_1$.


\section{Descubrimiento}

%% Si $\hat{\mu}$ y $\hat{\btheta}$ son los valores que maximizan $L(\mu,\btheta)$ o minimizan
%% $- \ln L(\mu, \btheta)$ y $\bdtheta$ es el valor que maximiza $L$ para un valor fijo de $\mu$
%% (the profile value of \btheta), el cociente de likelihood es,

Generalmente, cuando se modela un fenómeno aleatorio de interés, el modelo
elegido para ajustar a las observaciones de dicho fenómeno suele tener varios
parámetros, de los cuales solo algunos pueden ser de interés. De manera formal a
estos parámetros se los denomina parámetros de interés y al resto, parámetros
\emph{nuisance}, y conviene separarlos explícitamente $\btheta \to (\mu, \btheta)$.

Para la búsqueda de nueva física es común definir como parámetro de interés a la
intensidad de la señal de forma tal que la hipótesis de solo-fondo corresponde a
$\mu = 0$ , y la hipótesis de señal+fondo a $\mu = 1$.
BY, en general, las incertezas sistemáticas son incluidas en el modelo
utilizando parámetros nuisance.

En este escenario, donde tenemos un sólo parámetro de interés
$\mu$, y el resto de parámetros nuisance $\btheta$, es conveniente
definir el \emph{profile likelihood ratio} (PLR),

\begin{equation}
  \lambda(\mu) = \frac{L(\mu,\doublehat{\btheta})}{L(\hat{\mu},\hat{\btheta})}
  \label{eq:lambdamu}
\end{equation}
%
donde en el denominador, los valores $\hat{\btheta}$ y $\hat{\mu}$ son los
valores estimados MLE. Y en el numerador, los parámetros {$\doublehat{\btheta}$}
son los valores que maximizan la función likelihood para un valor fijo de $\mu$,
es decir que es una función multidimensional que depende solo del parámetro $\mu$.
Este proceso de elegir valores específicos de los parámetros
nuisance para un valor dado de $\mu$ se lo conoce como \emph{profiling}. El PLR
depende explícitamente de $\mu$ pero es independiente de los parámetros
nuisance que han sido ``eliminados'' vía el \emph{profiling}.
La presencia de los parámetros nuisance que son ajustados a los datos ensanchan
la función likelihood como función de $\mu$, respecto a la distribución si sus
valores estuvieran fijos. De cierta forma reflejan una pérdida de información
sobre $\mu$ debido a estos parámetros desconocidos, que suelen ser
las incertezas sistemáticas.

En la seccion anterior se mostro que el mejor test estadistico para hipotesis
simples esta dado por el cociente de los likelihoods de las dos hipotesis, de acuerdo
al teorema de Neyman-Pearson.
Desafortunadamente no hay un equivalente al lema de Neyman-Pearson para modelos
con muchos parámetros libres. Sin embargo, hay una generalización natural basada
en el PLR. De la \cref{eq:lambdamu} se puede ver que $0 \leq \lambda \leq 1$, con
$\lambda$ cercano a 1 implica un buen acuerdo entre datos y el valor hipotetico de $\mu$.
De forma equivalente conviene utilizar como estadistico de prueba $t_\mu = -2 \ln \lambda(\mu)$.
En el limite asintotico ($N\to\infty$) el teorema de Wilk\cite{WilkTheo} muestra
que $-2 \ln \lambda(\mu)$ sigue una distribucion $\chi^2$ con un grado de libertad.
Esta propiedad sera util para aproximar la pdf del estaditico
de prueba (ver \cref{sec:aprox}).


%% Entonces para este  caso de $\mu \geq 0$ conviene definir,

%% \begin{equation}
%%   \tilde{\lambda}(\mu) =
%%     \begin{cases}
%%       \frac{L(\mu, \doublehatfix{\btheta})}{L(\hat{\mu}, \hat{\btheta})} & \hat{\mu} \geq 0 \\
%%       \frac{L(\mu, \doublehatfix{\btheta})}{L(0, \hat{\btheta}(0))} & \hat{\mu} < 0
%%     \end{cases}
%% \end{equation}

%% Acá $\doublehat{\btheta}(0)$ y $\doublehat{\btheta}(\mu)$ se refieren a los MLE
%% de {\btheta} dados los parámetros de intensidad de señal parámetro de 0 o $\mu$
%% respectivamente. El correspondiente estadístico de prueba puede obtenerse como,

%% \begin{equation}
%%   \tilde{t}_\mu = -2 \ln \tilde{\lambda}(\mu) %% \begin{cases} %% -2 \ln  \frac{L(\mu, \hat{\hat{\bm{\theta}}})}{L(0, \hat{\bm{\theta}}(0))} & %%
%%   %%-\hat{\mu} < 0 \\ %%2 \ln \frac{L(\mu, \hat{\hat{\bm{\theta}}})}{L(\hat{\mu}, %%     -\hat{\bm{\theta}})} & \hat{\mu} \geq 0 %% \end{cases}
%% \end{equation}

Un caso de especial importancia del estadístico $t_\mu$ es cuando $\mu=0$.
Rechazar la hipótesis de $\mu=0$ es lo
que llamamos \emph{descubrimiento} de una nueva señal.
Aunque es cierto que un valor de $\hat{\mu}$ mucho menor a cero representa
evidencia contra el modelo de solo-fondo, este tipo de discrepancia no muestran
que los datos contengan eventos de señal. Es por este motivo que sólo se
considera que los datos no tienen un buen acuerdo con la hipótesis de solo-fondo
cuando $\hat{\mu}$ es mayor a cero.
%% En otros experimentos, como los de
%% oscilaciones de neutrinos por ejemplo, la hipótesis de señal puede predecir un
%% número mayor o menor de eventos con respecto a la hipótesis de no oscilaciones.
Para este caso se define $q_0$ como,

\begin{equation}
  q_0 =
  \begin{cases}
    -2 \ln \lambda(0) & \hat{\mu} > 0 \\
    0 & \hat{\mu} \leq 0
  \end{cases}
\end{equation}

Si los datos fluctúan de tal manera que haya menos eventos que los predichos por
el fondo, entonces $\hat{\mu} = 0$ y $q_0=0$. A medida que el número de
eventos crece por encima del número de eventos de fondo esperado (mayor
$\hat{\mu}$) el valor de $q_0$ es mayor, lo que corresponde a un incremento en
el nivel de incompatibilidad con la hipótesis de solo-fondo. Para cuantificar el
nivel de desacuerdo entre datos y la hipótesis de $\mu=0$ usando el valor
observado de $q_0$ se calcula el {\pvalue} como,

\begin{equation}
  p_0 = \int_{q_{0,\text{obs}}}^{\infty} f(q_0|\mu=0) \, dq_0
  \label{eq:p0}
\end{equation}

En el caso de que $p_0 \leq \epsilon$ donde $\epsilon$ es un tamaño del test
fijado anteriormente, se dice que hay un descubrimiento. En general en física de
altas energías suele utilizarse $\epsilon = 2.87 \times 10^{-7}$, el cual
corresponde a una significancia equivalente $Z=5\sigma$.

Es importante notar que el hecho de rechazar la hipótesis de solo-fondo en un
sentido estadístico es solo parte de descubrir un fenómeno nuevo.
Para confirmar la presencia de este nuevo fenómeno es necesario estudiar
el acuerdo de este para describir los datos observados.


\section{Límites de Exclusión}

Por el contrario, si $p_0> \epsilon$ no se puede rechazar $H_0$. Esto no
significa que todos los valores de $\mu$ bajo $H_1$ estén excluidos.
En particular, hay valores de $\mu$ a los que el analisis no es sensible
y valores que los datos observados no permite excluir.

Para establecer limites superiores en el parametro $\mu$ se considera
$q_\mu$,

\begin{equation}
  q_\mu =
  \begin{cases}
    -2 \ln \lambda(\mu) & \hat{\mu} \leq \mu \\
    0 & \hat{\mu} > \mu
  \end{cases} \label{eq:qmu}
\end{equation}

%% Conviene notar que para establecer un límite superior, una fluctuación hacia
%% arriba de los datos no representa una mayor incompatibilidad de la hipótesis
%% $\mu$.
La razón para poner $q_\mu = 0$ para $\hat{\mu} > \mu$ es que cuando se
establece un límite superior, el hecho de que $\hat{\mu} > \mu$ representa menos
compatibilidad con $\mu$ que los datos obtenidos, y por lo tanto no se considera
parte de la región de rechazo de la constrastación.

También es importante notar, que $q_0$ (utilizado como estadístico de prueba para
descubrimiento) no es simplemente un caso especial de la
\cref{eq:qmu}, sino que tiene una definición diferente. Es decir, $q_0$ es cero
si los datos fluctúan hacia abajo ($\hat{\mu}<0$), pero $q_\mu$ es cero si los
datos fluctúan hacia arriba ($\hat{\mu}>\mu$).

%%Para los datos observados se tiene $\tilde{q}_\mu^\text{obs}$.
%% Para generar la
%% distribución de $\tilde{q}_\mu$ se pueden generar pseudo-experimentos con Monte
%% Carlo $\to$ $f(\tilde{q}_\mu|\mu, \btheta)$.

%% El {\pvalue} para una observación bajo una hipótesis $\mu$ es la
%% probabilidad de obtener un resultado igual o mas extremo que los obtenidos dado
%% H.

%% \begin{equation}
%%   p_{(\mu,\btheta)} = \int_{q_{\mu,\text{obs}}}^{\infty}
%%   f(q_\mu|\mu,\btheta) \, dq_\mu
%% \end{equation}
%% \begin{equation}
%%   p_{\mu} = \int_{q_{\mu,\text{obs}}}^{\infty}
%%   f(q_\mu|\mu) \, dq_\mu
%% \end{equation}

%% Este {\pvalue} presenta como dificultad que no solo depende del parámetro de interés,
%% sino también de $\btheta$. La hipótesis no puede ser rechazada a menos que
%% el {\pvalue} sea suficientemente chico para todos los valores de $\btheta$. De forma
%% equivalente se utiliza el supremo del {\pvalue} para decidir si la hipótesis de $\mu = \mu_0$
%% es aceptada o rechazada.

%% \begin{equation}
%%   p_\mu^\text{sup} = \sup_\theta p_{(\mu,\btheta)}
%% \end{equation}

%% La mayor razón para usar PLR como estadístico de prueba es que en el límite de muchos
%% eventos la distribución del PLR $\lambda(\mu=\mu_\text{0})$ es independiente
%% de los valores de los parámetros nuisance $p_\mu^\text{sup} = p_{(\mu,\btheta)}
%% \, \forall \theta$. Esto es una consecuencia del Teorema de Wilk.
%% Elegir $\btheta^\text{sup} = \doublehat{\btheta}(\mu)$, es decir, el valor para el
%% cual $p_{(\mu,\btheta)} = p_\mu^\text{sup}$ es un buen valor estimado de
%% $\btheta^\text{sup}$.

Para cuantificar la consistencia de los datos observados con la hipótesis de
intensidad de se\~nal $\mu$ se calcula el {\pvalue}

\begin{equation}
  p_\mu = \int_{q_{\mu,\text{obs}}}^{\infty} f(q_\mu|\mu) \, dq_\mu \equiv \clsb
  \label{eq:pmu}
\end{equation}
%
donde valores chicos de $p_\mu$ indican baja compatibilidad con la hipótesis
de señal+fondo.

El intervalo de confianza o límite superior con un nivel de
confianza del 95\% se obtiene resolviendo la siguiente ecuación:

\begin{equation}
  p_{\mu_\text{up}} = 0.05
\end{equation}

Sin embargo el límite superior calculado de esta forma tiene un problema: de
acuerdo a este se dice que una señal está excluida a 95\% CL, si ${\clsb} \leq
0.05$. Si se considera el caso de $\mu=0$, se espera que por construcción el
{\clsb} sea menor o igual que 0.05 con una probabilidad de 5\%. Esto significa
que el 5\% de los análisis estarían excluyendo modelos con cero señal. Otro
problema del {\clsb} es que para dos experimentos con el mismo número chico de
eventos de señal esperado pero con un numero de eventos de fondo distinto, el
experimento con mayor fondo va a imponer mejores límites.

Con motivo de solucionar estos inconvenientes se introduce el método de {\cls}\cite{ReadCLs}.
%% Se define el {\clb},

%% Los intervalos de confianza frecuentistas cubren e
%% Un limite superior con 95\% de nivel de confianza cubre al valor verdadero con una probabilidad de
%% 95\%. Eso sinifica que un 5\% de las veces no lo cubre. Esto significa, que si no hay senal, el 5\% de las veces
%% se esta excluyendo cualquier valor positivo de XS.

\begin{equation}
  \cls = \frac{p_\mu}{1-p_b}  \equiv \frac{\clsb}{\clb}
\end{equation}
%
donde $p_b$ es el valor del mismo test bajo la hipótesis de solo-fondo,

\begin{equation}
  1 - p_b = \int_{q_\mu^\text{obs}}^{\infty}
  f({q}_\mu|0) \, dq_\mu \equiv \clb
\end{equation}

El límite superior {\cls} en $\mu$, $\mu_\text{up}$ se obtiene resolviendo
$p_{\mu_\text{up}} = 0.05$. Se rechazan los valores de $\mu$ si $\mu <
\mu_\text{up}$ con un nivel de confianza de 95\%.

Para una observación cercana al número de eventos esperado de sólo-fondo ($\clb
\sim 0.05$) el {\cls} da un valor del orden de dos veces el obtenido utilizando
el {\clsb}.
%% Entonces, el método {\cls} evita no sólo el problema descripto anteriormente, sino también
%% la propiedad indeseable del {\clsb} que para dos


% -----------------------
% Aproximacion asintotica
% -----------------------
\section{Aproximación asintótica}\label{sec:aprox}

Para poder calcular el {\pvalue} de una hipótesis utilizando las ecuaciones
\eqref{eq:p0} y \eqref{eq:pmu} se necesita conocer las distribuciones muestrales
del estadístico de prueba, $f(q_\mu)$.


Como se dijo anteriormente, el teorema de Wilk establece que para el limite de
$N\to\infty$, el estadistico de prueba $t_\mu = -2\ln \lambda$ sigue una
distribucion $\chi^2$ con un grado de libertad, cuando la hipotesis nula es verdadera.

El teorema de Wald\cite{WaldTheo} generaliza este teorema para el caso de la hipotesis no nula.
En este caso el estadisitico $-2\ln\lambda$ sigue una distribucion $\chi^2$ no central.


La distribucion $f(q_\mu|\mu')$ puede encontrarse utiliznaod los resultados de Wald[],
que mostro que para el caso de un solo parametro de interes vale:

\begin{equation}
  -2 \ln \lambda(\mu) = \frac{(\mu - \hat{\mu})^2}{\sigma^2} + \mathcal{O}(1/\sqrt{N})
\end{equation}
%
donde $\hat{\mu}$ sigue una distribucion normal con media $\mu'$ y desviacion estandar $\sigma$.
Si $\hat{\mu}$ se encuentra distribuido normalmente y se desprecian los terminos $\mathcal{O}(1/\sqrt{N})$,
se puede mostrar que en el regimen asintotico, el estadistico $t_\mu$ sigue una distribucion $chi^2$ no central
con un grado de libertad.

Entonces, en el límite asintótico, el estadistico $t_\mu$ puede aproximarse por

\begin{equation}
  q_\mu =
  \begin{cases}
    \frac{(\mu-\hat{\mu})^2}{\sigma^2} & \hat{\mu} \leq \mu \\
    0 & \hat{\mu} > \mu
  \end{cases}
\end{equation}
%
y el {\pvalue} de la hipotesis $H_\mu$ es,

\begin{equation}
  p_\mu = \int_{q_{\mu,\text{obs}}}^{\infty} f(q_\mu|\mu) \, dq_\mu = 1 - \Phi(\sqrt{q_\mu})
\end{equation}
%
y su correspondiente significancia equivalente,

\begin{equation}
  Z_\mu = \Phi^{-1}(1-p_\mu) = \sqrt{q_\mu}
\end{equation}

Siguiendo los mismos argumentos, el estadistico $q_0$ puede aproximarse con,

\begin{equation}
  q_0 =
  \begin{cases}
    \frac{(\hat{\mu})^2}{\sigma^2} & \hat{\mu} \geq 0 \\
    0 & \hat{\mu} < 0
  \end{cases}
\end{equation}

El {\pvalue} para $H_0$ entonces es,

\begin{equation}
  p_0 = \int_{q_{0,\text{obs}}}^{\infty} f(q_0|0) \, dq_0 = 1 - \Phi(\sqrt{q_0})
\end{equation}
%
y la correspondiente significancia,

\begin{equation}
  Z_0 = \Phi^{-1} (1-p_0) = \sqrt{q_0}
\end{equation}

Estas aproximaciones permiten conocer las distribuciones muestrales y calcular
{\pvalue}s y significancias en el caso de un gran número de datos, de una forma
simple y computacionalmente poco costosa.
A pesar de que estrictamente es valido para $N\to\infty$, esta aproximacion es suficientemente
precisa para un numero de eventos de fondo $\smallrel\gtrsim \mathcal{O}(10)$.

Para muestras de datos muy pequeñas, o en casos donde la precisión es
importante, siempre pueden validarse estas aproximaciones utilizando la
generación Monte Carlo.

Para esto es necesario utilizar simulaciones Monte Carlo para
generar lo que se denomina \emph{pseudo-experimentos}. El procedimiento
consiste en generar el conjunto de observables $\bm{x}$ utilizando la pdf
$f(\bm{x}|H)$ y calcular el valor del estadístico de prueba $t(\bm{x})$ para
cada conjunto. Este proceso se repite hasta acumular suficiente estadística
en la distribución muestral del estadistico $g(t|H)$.



% ----------------------
% Significancia esperada
% ----------------------
\section{Significancia esperada}

En física de partículas la cantidad $s/\sqrt{b}$ ha sido siempre utilizada como
una medida de la significancia esperada de descubrimiento. La explicación detrás
de esta formula es que una cantidad $n$ que sigue una distribución de Poisson
con una media grande $s+b$ puede ser aproximada por una variable $x$
distribuida según una gaussiana con media $s+b$ y desviación estándar
$\sqrt{s+b}$. En este caso el valor-$p$ de la hipótesis de sólo-fondo dada una
observación $x$ esta dado por,

\begin{equation}
  p = 1 - \Phi \left( \frac{x-\mu}{\sigma} \right) = 1 - \Phi \left(
  \frac{x-b}{b} \right)
\end{equation}
%
donde $\mu=b$ y $\sigma = \sqrt{b}$ se refieren a la media y la desviación
estándar de $x$ suponiendo que $s=0$. Traduciendo este {\pvalue} a significancia,

\begin{equation}
  Z = \frac{x-b}{b}
\end{equation}

La significancia esperada, a diferencia de la observada, se calcula desde la mediana
de la hipótesis alternativa. Entonces como la mediana de la hipótesis de señal+fondo,
en este caso igual a la media, es $s+b$,

\begin{equation}
  Z_\text{exp} = \frac{s}{\sqrt{b}}
  \label{eq:Zsimple}
\end{equation}
%
que es la ecuación conocida. %% Y para generalizar esta ecuación para el caso de que el
%% numero de eventos de fondo tenga una incerteza sistemática

%% utilizando la aproximación
%% asintotica de la seccion anterior,
De forma general, para el caso un número de eventos de fondo $b$ conocido con
una incerteza despreciable, se puede escribir la función likelihood como,

\begin{equation}
  L(s) = \frac{(s+b)^n}{n!} e^{-(s+b)}
\end{equation}
%
y utilizando la aproximación asintótica, la significancia de descubrimiento
puede ser aproximada por $Z=\sqrt{q_0}$, lo que da como resultado,

%% \begin{equation}
%%   Z = \sqrt{2\left( n \ln \frac{n}{b} +b -n \right)}
%%   \label{eq:Z}
%% \end{equation}
%
%% para $n>b$ y $Z=0$ para $n<b$. También puede aproximarse la significancia esperada
%% reemplazando los datos por el conjunto de datos de Asimov. Substituyendo $s+b$
%% por $n$ en la {\eq} \eqref{eq:Z}, la aproximaxion de Asimov para la
%% significancia esperada $Z_A$ es,

\begin{equation}
  Z_A = \sqrt{2\left( (s+b) \ln \left( 1 + \frac{s}{b}\right) - s \right)}
  \label{eq:Z}
\end{equation}

Si expandimos el logaritmo en la ecuación anterior en $s/b$ tenemos $Z_A =
s/\sqrt{b} + \mathcal{O}(s/b)$ que es la expresión de la {\eq}
\eqref{eq:Zsimple} y es válida sólo en el límite $s \ll b$.

Si el número de eventos esperado de fondo $b$ no es conocido, uno debe incluirlo
como un parámetro nuisance en la función likelihood. Pero como $b$ puede
ajustarse para cualquier número de eventos, es necesario introducir información
adicional para restringir $b$. En general se suele hacer mediante una medida
auxiliar, mirando el número de eventos observados $m$ en una región de control
donde se supone ausencia de señal, y considerando que $m$ sigue
una distribución de Poisson con media $\tau b$, donde $\tau$ es un factor de
extrapolación.

La función likelihood total es el producto de las dos distribuciones de Poisson
correspondientes a cada región:

\begin{equation}
  L(\mu, \btheta) = \Pois (n;s+b) \Pois(m;\tau b)
\end{equation}

Utilizando la aproximación $Z = \sqrt{q_0}$, valida en el límite de una muestra
grande de datos y teniendo en cuenta que los valores esperados son $s+b$ y $\tau
b$ para obtener la significancia esperada, tenemos:

\begin{equation}
  Z_A = \left[ 2 \left( (s+b) \ln \left[ \frac{s+(1+\tau)b}{(1+\tau)(s+b)}
      \right] + \tau b \ln \left[ 1 + \frac{s}{(1+\tau)b} \right] \right)
    \right]^{1/2}
  \label{eq:Za1}
\end{equation}

Es útil expresar la \cref{eq:Za1} en términos de la incerteza que uno
quiere atribuirle al fondo basados en la medida de control $m$. El estimador
para $b$ esta dado por $\hat{b} = m/\tau$, y como la varianza de $m$ es igual a
su media $\tau b$, la varianza de $\hat{b}$ es $V[\hat{b}] = \sigma_b^2 =
b/\tau$. Usando esto para eliminar $\tau$ de la \cref{eq:Za1}
obtenemos:

\begin{equation}
  Z_A = \left[ 2 \left( (s+b) \ln \left[
      \frac{(s+b)(b+\sigma_b^2)}{b^2+(s+b)\sigma_b^2} \right] -
    \frac{b^2}{\sigma_b^2} \ln \left[ 1 + \frac{\sigma_b^2 s}{b(b+\sigma_b^2)}
      \right] \right) \right]^{1/2}
  \label{eq:Za}
\end{equation}
%
y, expandiendo en potencias de $s/b$ y $\sigma_b^2/b$, obtenemos,

\begin{equation}
  Z_A = \frac{s}{\sqrt{b+\sigma_b^2}} \left( 1 + \mathcal{O}(s/b) + \mathcal{O}(\sigma_b^2/b) \right)
\end{equation}
%
que es la ecuación conocida, válida cuando $s\ll b$ y $\sigma_b^2 \ll b$.

\cite{medSigNote}



%% \subsection{Psuedo-experimentos}

%% The role of intervals in Search Procedures

%% Exclusion A signal hypothesis can be excluded if the compatibility with the s C b
%% hypothesis is ‘small’. Several limit-setting methods exist and are a source of in-
%% tense discussions among physicists, to say the least (see also Section 4.6). Although
%% it might seem natural to define a signal as excluded at 95% confidence level if
%% CL sCb < 5%, there are some undesirable consequences associated with this choice.
%% Near the sensitivity limit, where the test statistic distribution for the b-only and sCb
%% hypotheses are not well separated (either because the signal is small or the analysis
%% is not powerful enough to separate signal and background), a downward fluctua-
%% tion in the data with respect to the b-only expectation will result in the exclusion
%% of a signal while the analysis has no real sensitivity. One of the common solutions

%% experiments invoke to address this issue is to correct for a downward fluctuation
%% by using the so-called CL s method [6], where a signal is called ‘excluded’ at 95%
%% confidence level if CL s < 0.05, where CL s


%% Para ilustrar el uso del likelihood ratio, consideremos un experimento en el cual por cada evento,
%% se miden los valores de ciertas variables cinematicas, entonces los datos pueden ser representados
%% por uno o mas histogramas.

%% Supongamos el histograma $\vec{n} = (n_1, n_2, \ldots, n_n)$. El valor esperado para $n_i$ puede
%% escribirse $E[n_i] = \mu s_i + b_i$, donde el valor medio de entradas del bin $i$ de se\~nal y fondo
%% son:

%% El parametro $\mu$ determina la intensidad de la nueva se\~nal, donde $\mu=0$ corresponde a la
%% hipotesis de solo-fondo, y $\mu=1$ es la hipotesis de se\~nal.
%% Las funciones $f_s$ y $f_b$ son las \pdf\ de la variable x para los eventos de se\~nal y fondo, y
%% $\theta_s$ y $\theta_b$ representan parametros que caracterizan la forma de las pdfs. Las
%% cantidades $s_\text{tot}$ y $b_\text{tot}$ son el valor medio total de se\~nal y fondo, y las
%% integrales en \ref{} y \ref{} representan la probabilidad de que un evento sea encontrado en el
%% bin $i$. En lo que sigue $\bm{\theta} = (\bm{\theta}_s, \bm{\theta}_b, b_\text{tot})$

%% Además del histograma $\bm{n}$, se utilizan otras medidas adicionales que ayuden a restringir
%% los parametros nuisance. Por ejemplo, se pueden elegir regiones de control donde uno espera
%% mayormente fondo, y construit un histograma $\bm{m}$. Los valores esperados de $m_i$ pueden
%% escribirse como $E[m_i] = u_i(\bm{\theta})$, donde los $u_i$ son cantidades calculadas a partir
%% de $\bm{\theta}$.

%% \itodo{
%%   It is often said that the language of science is mathematics. It could well be said that the language of experimental science is statistics.
%%   It is through statistical concepts that we quatify
%%   the correspondence between theoretical predicticions and experimental observations. While the statistical
%%   analysis of the dta is often treated as a final subsidiary step to an experimental physcis
%%   result, a more direct approach would be quite the opposite. In fact, thinking through the
%%   requirements for a robust statistical statement is an excellent way to organize an analysis
%%   strategy.
%%   }


%% Referencias

%% AsymAprox, Cowan discovery sensitive, HistFitter paper, Kramer Practical.., Wilds theo., Walds theo.
%% HistFactory manual, presentation of cls technique, libro de cowan y libro de james.
