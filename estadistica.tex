\chapter{Métodos estadísticos para la búsqueda de nueva física}

En este capítulo se introducen los conceptos básicos necesarios para entender el
tratamiento estadístico de los datos. Esta enfocado en la búsqueda de nueva
física en altas energías, su descubrimiento y/o el establecimiento de límites de
exclusión.


\section{Introducción} %Probabilidad y axiomas de Kolmogorov, teorema de Bayes}

Dada la naturaleza probabilística de las colisiones en el LHC y el bajo número
de eventos esperados en las búsquedas de nueva física, es necesario contar con
un poderoso marco estadístico para interpretar los resultados, especialmente
para identificar una nueva señal sobre las posibles fluctuaciones de los fondos
del SM.

Un observable $x$ es por naturaleza \emph{frecuentista}, es decir, si realizamos
el experimento muchas veces, vamos a obtener distintos valores para $x$ y este
conjunto de valores va a dar lugar a una función densidad de probabilidad (pdf)
de $x$, que llamamos $f(x)$. En el caso más general, lo que hay es una familia
de pdfs $f(x;\btheta)$ a la cual se denomina \emph{modelo}. Los parámetros del
modelo representan, por ejemplo, parámetros de la teoría física, alguna
propiedad desconocida de la respuesta del detector, o incertezas sistemáticas
del análisis.


\section{Distribución de Poisson}

La distribución de Poisson es una distribución de probabilidad discreta que
describe, a partir de una frecuencia de ocurrencia media, la probabilidad de que
ocurra un determinado número de eventos durante cierto período de tiempo. Un
ejemplo típico que puede ser descripto por esta distribución es el número de
clicks de un contador Geiger en un determinado intervalo de tiempo.

Se la puede pensar como un límite de la distribución binomial cuando el número
de experimentos tiende a infinito y la probabilidad a cero, pero el producto es
constantes $Np = \nu$. En ese caso la función de probabilidad esta dada por:

\begin{equation}
  \Pois(n;\nu) = \frac{\nu^n}{n!} e^{-\nu}
\end{equation}

Su valor esperado es $E[n] = \nu$ y la varianza $V[n] = \nu$.
Cuando $\nu \to \infty$ la distribución de Poisson converge a una distribución
normal de media $\nu$ y ancho $\sqrt{\nu}$.


\section{Estimadores}

La estimación de parámetros de las distribuciones observadas es una de las
tareas fundamentales del análisis de datos, y puede considerarse como la
medición de un parámetro (que tiene un valor fijo pero desconocido) basado en un
número limitado de observaciones experimentales. Dado el experimento, la
estimación puntual consiste en determinar un valor único lo mas cerca posible al
valor verdadero.%% , y la estimación de un intervalo es determinar
%% un rango de valores que contengan al valor verdadero del parámetro.

Supongamos un conjunto de $N$ observaciones $\bm{x} = (x_1, x_2, \ldots, x_N)$,
donde las medidas $x_i$ son estadísticamente independientes y cada una está
descripta por una función de densidad de probabilidad $f(x;\btheta)$ que no
conocemos, donde $\btheta$ es un conjunto de parámetros con valores
desconocidos, que tienen un valor verdadero $\btheta_0$.

%Uno quiere estimar las distintas
%caracteristicas de la funcion como su media o varianza, o $f(x;\theta)$...

Un \emph{estimador} es una función de los datos observados $\bm{x}$ que provee
valores numéricos, los valores estimados $\hat{\btheta}$, para el vector de
parámetros $\btheta$.

Algunas propiedades que es importante que cumplan los estimadores son:

\begin{itemize}\itemsep0.2cm\parskip0.2cm
\item {\bf Consistencia:} Un estimador se dice consistente (o asintóticamente
  consistente) si converge al valor verdadero $\btheta_{0}$ con el número de
  medidas $N$: $\lim_{N \to \infty} \hat{\btheta} = \btheta_0$.

\item {\bf Sesgo:} El sesgo esta definido como la diferencia entre el valor
  esperado del estimador y el valor verdadero: $E[\hat{\btheta}] - \btheta_0$ y
  un estimador es no sesgado cuando el sesgo es cero.

\item {\bf Eficiencia:} Un estimador es eficiente si su varianza
  $V[\hat{\btheta}]$ es chica.
\end{itemize}

Los dos métodos mas utilizados para la estimación de parámetros son el de
\emph{likelihood máximo} y el de \emph{mínimos cuadrados}.


\subsection{Método del likelihood máximo}\label{sec:MLE}

Para $N$ mediciones estadísticamente independientes la pdf conjunta para los
valores observados $x$ esta dada por $f(\bm{x}, \btheta) = \prod_i f(x_i,
\btheta)$. La función \emph{likelihood} se define como la pdf evaluada en los
datos observados,

\begin{equation}
  L(\btheta) = f((x_1, x_2, \ldots, x_n); \btheta) = \prod_{i=1}^{N} f(x_i;
  \btheta)
\end{equation}

El estimador de máximo likelihood (MLE) de los parámetros {\btheta} son los
valores $\hat{\btheta}$ para los cuales la función likelihood $L(\btheta)$ tiene
su máximo global. %% Una forma intuitiva de ver esto es la siguiente: si
asumimos
%% que la pdf y los parámetros son correctos, esperamos valores altos de la función
%% likelihood comparado con otros parámetros que no sean los verdaderos.

%% Los valores estimados $\hat{\btheta}$ de los parámetros se obtienen buscando el
%% máximo global de la función likelihood.
En la practica, es conveniente trabajar con el logaritmo de la función
likelihood (log-likelihood), y buscar el mínimo del negativo de esta función:

\begin{equation}
  - \ln L(\btheta) = \sum_{i=1}^{N} \ln f(x_i; \btheta)
\end{equation}

\begin{equation}
  - \pd{\ln L(\hat{\btheta})}{\theta_j} = 0 \qquad \text{para} \qquad j =
  1,\ldots,m.
\end{equation}

En el límite asintótico, cuando el número de mediciones $N$ tiende a infinito,
el MLE es consistente, es decir, para cada parámetro $\theta$ el valor estimado
$\hat{\theta}$ converge al valor verdadero $\theta_0$. En este límite también el
MLE es no sesgado y tiene su menor varianza. Esto significa que ningún otro
estimador puede ser más eficiente. Para un número finito de eventos $N$, sin
embargo, el MLE tiene un sesgo proporcional a $1/N$.

Generalmente, cuando se modela un fenómeno aleatorio de interés, el modelo
elegido para ajustar a las observaciones de dicho fenómeno suele tener varios
parámetros, de los cuales sólo algunos pueden ser de interés. De manera formal a
estos parámetros se los denomina parámetros de interés y al resto, parámetros
\emph{nuisance}, y conviene separarlos explícitamente $\btheta \to (\mu,
\btheta)$. En general, las incertezas sistemáticas son incluidas en el modelo
utilizando parámetros nuisance. Estos parámetros no se considera conocidos a
priori, sino que se ajustan a los datos.

En este escenario, donde tenemos un sólo parámetro de interés
$\mu$, y el resto de parámetros nuisance $\btheta$, es conveniente
definir el \hl{profile likelihood ratio} (PLR),

\begin{equation}
  \lambda(\mu) = \frac{L(\mu,\doublehat{\btheta})}{L(\hat{\mu},\hat{\btheta})}
\end{equation}
%
donde en el denominador, los valores $\hat{\btheta}$ y $\hat{\mu}$ son los
valores estimados MLE. Y en el numerador, los parámetros {$\doublehat{\btheta}$}
son los valores que maximizan la función likelihood para un valor fijo de $\mu$,
es decir que es una función multidimensional que depende del parámetro $\mu$.
Este proceso de elegir valores específicos de los parámetros
nuisance para un valor dado de $\mu$ se lo conoce como \emph{profiling}. El PLR
depende explícitamente de $\mu$ pero es independiente de los parámetros
nuisance que han sido ``eliminados'' vía el \emph{profiling}.

La presencia de los parámetros nuisance que son ajustados a los datos ensanchan
la función likelihood como función de $\mu$, respecto a la distribución si sus
valores estuvieran fijos. De cierta forma reflejan una perdida de información
sobre $\mu$ debido a estos parámetros desconocidos, que suelen ser
las incertezas sistemáticas.

%% Segun el Teorema de Wilk, en el límite de $N$ grande, donde la función
%% likelihood se aproxima a una distribución gaussiana, el cociente de likelihoods
%% sigue una distribución $\chi^2$ con $m$ grados de libertad.\note{Que es m?
%%   Teorema de Wilk?}


\subsubsection{Likelihood máximo extendido}

Cuando se repite un experimento con las mismas condiciones muchas veces, el
número de eventos $n$ de un proceso va a fluctuar de acuerdo a una distribución
de Poisson alrededor del valor esperado $\nu$. Este término de Poisson puede
incorporarse entonces a la función likelihood, obteniendo lo que llamamos
\emph{likelihood extendido}:

\begin{equation}
  L(\nu,\btheta) = \Pois(n;\nu) \prod_{i=1}^{N} f(x_i; \btheta)
\end{equation}


\subsection{Estimación de intervalos}

%% En la \cref{sec:MLE} se muestra el metodo que se utilizada para estimar un
%% parámetro, es decir, como encontrar el valor que mejor represente un cierto
%% parámetro de interés, dados los datos observados.

La estimación de intervalos, a diferencia de la estimación puntual,
consiste en proveer un intervalo de valores, y un nivel de
confianza sobre como el valor verdadero del parámetro de interés yace entre esos
límites. La idea es encontrar un rango $\mu_a \leq \mu \leq \mu_b$, tal
que contenga al valor verdadero $\mu_0$ con una probabilidad $\alpha$. Este
intervalo es llamado \emph{intervalo de confianza} con un nivel de confianza
$\alpha$.

La construcción de estos intervalos se puede realizar utilizando el método que
se debe a \note{Agregar referencia}Neyman, o utilizando un método alternativo.
%%Supongamos que conocemos la distribución muestral
%% $g(\hat{\btheta}, \btheta)$. Esta distribución depende del valor verdadero
%% $\theta$ que no conocemos, pero a pesar de eso, podemos conocer la distribución
%% $g(\hat{\btheta})$ para un dado valor del parámetro.

%% Para construir el intervalo, tenemos que especificar una probabilidad superior e
%% inferior $\alpha$ y $\beta$, y luego las funciones $u_\alpha(\theta)$ y
%% $v_\beta(\theta)$ tal que:

%% \begin{align}
%%   \alpha &= P(\hat{\theta} \geq u_\alpha(\theta)) =
%%   \int_{u_\alpha(\theta)}^{\infty} g(\hat{\theta};\theta) \, d\hat{\theta}
%%   \\ \beta &= P(\hat{\theta} \leq v_\beta(\theta)) =
%%   \int^{v^\beta(\theta)}_{-\infty} g(\hat{\theta};\theta) \, d\hat{\theta}
%% \end{align}


%% \begin{figure}[h]
%%   \centering
%%   \input{tikz/stat_interval_construction2.tex}
%% \end{figure}


%% La región dentro de $u_\alpha(\theta)$ y $v_\beta(\theta)$ es llamada cinturón
%% de confianza (ver figura \XXX), y la probabilidad del estimador de estar dentro
%% de este cinturón (sin importar el valor de $\theta$) es,

%% \begin{equation}
%%   P(v_\beta(\theta) \geq \hat{\theta} \geq u_\alpha(\theta)) = 1 -\alpha - \beta
%% \end{equation}

%% Se pueden encontrar las funciones inversas $a(\hat{\theta})$ y $b(\hat{\theta})$
%% de $u$ y $v$, y para estas se cumple que,

%% \begin{equation}
%%   P(a(\hat{\theta}) \geq \theta \geq b(\hat{\theta})) = 1 -\alpha - \beta
%% \end{equation}

%% Si evaluamos las funciones $a$ y $b$ en el valor observado
%% $\hat{\theta}_\text{obs}$ se obtienen el intervalo $[a,b]$. Este intervalo es el
%% intervalo de confianza a un nivel de confianza (\emph{CL}) de $1-\alpha-\beta$.
%% Esto significa que si el experimento se realiza muchas veces, el intervalo
%% $[a,b]$ va a incluir el valor verdadero de $\theta$ en una fracción
%% $1-\alpha-\beta$ de las veces.

%% El valor $a$ representa el límite inferior en el parámetro $\theta$ tal que
%% $a\leq\theta$ con probabilidad $1-\alpha$, y $b$ representa el límite superior
%% en $\theta$ tal que $P(\theta \leq b) = 1-\beta$. Por construcción, el valor de
%% $a$ da el valor hipotético del valor verdadero de $\theta$ para el cual una
%% fracción $\alpha$ de los valores estimados $\hat{\theta}$ va a ser mayor al
%% observado $\hat{\theta}_\text{obs}$, y lo mismo sucede con $b$. Tomando
%% $\hat{\theta}_\text{obs} = u_\alpha (a) = v_\beta (b)$,

%% \begin{align}
%%   \alpha &= \int_{\hat{\theta}_\text{obs}}^{\infty} g(\hat{\theta};a) \,
%%   d\hat{\theta} \\ \beta &= \int^{\hat{\theta}_\text{obs}}_{-\infty}
%%   g(\hat{\theta};b) \, d\hat{\theta}
%% \end{align}

%% Otra forma equivalente de encontrar el intervalo de confianza para $\theta$ es
%% definir un test para el valor hipotético de $\theta$ y realizar este test por
%% cada $\theta$, y obtener el {\pvalue} $p_\theta$ tal que si $p_\theta < \gamma$
%% rechazamos $\theta$. El intervalo de confianza consiste entonces en los valores
%% de $\theta$ que no fueron rechazados en el test de tamaño $\gamma$, con un nivel
%% de confianza $1-\gamma$.

Este método equivalente para construir intervalos de confianza consiste en
considerar la hipótesis de que el valor verdadero del parámetro es $\mu$ y
realizar un test de hipótesis (ver \cref{sec:testhypo}) para cada valor de
$\mu$, y se obtiene el {\pvalue} $p_\mu$ tal que si  $p_\mu \leq \alpha$
se rechaza $\mu$. El intervalo de confianza consiste entonces en los valores
de $\mu$ que no fueron rechazados con el test de tamaño $\alpha$, con un
nivel de confianza $1-\alpha$. Es decir que los límites del intervalo de
confianza se encuentran resolviendo $p_\mu = \alpha$ para todo $\mu$.


\section{Contrastación de hipótesis}
\label{sec:testhypo}

En la sección anterior se describió como pueden utilizarse los datos observados
para estimar parámetros. En esta sección se describirá como estos datos
experimentales también pueden ser usados para contrastar hipótesis, es decir,
para verificar o rechazar una teoría o hipótesis, o también para elegir entre
hipótesis alternativas. Cuando la hipótesis a contrastar concierne el valor de
un parámetro, estos dos temas están relacionados, aunque no hay que confundirlos.

Se llama hipótesis nula, $H_0$, a la hipótesis sujeta a la prueba y usualmente
corresponde a la hipótesis que consideramos verdadera. Esta hipótesis es
comparada contra una (o varias) hipótesis alternativa $H_1$ distinta a $H_0$.

En el caso de búsqueda de nueva física, la hipótesis que juega el rol de
hipótesis nula es la hipótesis de que sólo los procesos del SM contribuyen a las
mediciones. Esta hipótesis también suele llamarse hipótesis de
\emph{sólo-fondo}. Y la hipótesis alternativa es la hipótesis en la cual, además
de los procesos del SM, también contribuyen procesos de nueva física y se
denomina hipótesis de \emph{se\~nal+fondo}.

Una hipótesis se dice \emph{simple} cuando esta completamente determinada. En
cambio, cuando tiene uno o más parámetros libres, se dice \emph{compuesta}, y
en este caso consiste en una familia de hipótesis simples. Cada hipótesis queda
determinada por la pdf que describe a los observables bajo esa hipótesis
$f(\bm{x}|H)$.

Una vez definidas las hipótesis, se quiere saber si los datos medidos son
compatibles con la hipótesis nula o si la hipótesis nula puede ser rechazada en
base a estos datos. Con este objetivo se define un \emph{estadístico de prueba}
$t(\bm{x})$ que es función de los datos observados: $t(\bm{x}) \to \mathbb{R}$.
El estadístico de prueba $t(\bm{x})$ contiene toda la información de
discriminación entre $H_0$ y $H_1$ en un sólo número.
%% El lema de
%% Neyman-Pearson prueba que el estadistico de prueba con mayor
%% poder de discriminacion es el cociente de likelihoods es el
%% discriminador mas poderoso \todo{buscar referencia}. %%El cociente de
%% likelihoods se define como

Cada estadístico de prueba tendrá su pdf asociada $g(t|H)$ y la decisión sobre
la hipótesis estará basada en el valor del estadístico observado $t_\text{obs}$
y la definición de una \emph{región critica} $R$. La región critica queda
definida por un valor de corte $t_c$ y para el caso de que la hipótesis
alternativa tiende a tener valores de $t$ mayores que bajo $H_0$, la región
critica corresponde a $t \geq t_c$ (ver \cref{fig:stat_test}).

Si el valor observado se encuentra fuera de la región critica (dentro de la
región de aceptancia) la hipótesis $H_0$ no puede ser rechazada, y si esta
dentro esta es rechazada.

\begin{figure}[h]
  \centering \input{tikz/stat_test.tex}
  \caption{Funciones de densidad de probabilidad para el estadístico de prueba
    $t$ bajo la hipótesis nula $H_0$ (azul) y la hipótesis alternativa $H_1$
    (rojo). Las regiones de aceptaciancia y rechazo quedan definidas por $t_c$.}
  \label{fig:stat_test}
\end{figure}

%% Asumiendo que $H_0$ es verdadera, se puede definir una región critica $R$ tal que la probabilidad
%% de que $q$ pertenezca a $R$ sea igual o menor a un cierto valor. El hecho de que $q_\text{obs}$
%% este dentro de $R$, implica que $H_0$ sea rechazada, y de lo contrario aceptada.

%% Primero se define una \emph{región de aceptancia}, tal que si $T(\mathcal{d}) < k_\alpha$
%% uno acepta la hipótesis nula. El contorno $T(\mathcal{d}) = k_\alpha$ delimita el espacio de datos,
%% y es el borde de la región de aceptancia. Se define el tamaño del test, $\alpha$, como la
%% probabilidad de que la hipótesis nula sea rechazada en el caso de ser verdadera (lo que se conoce
%% como error de tipo I). Esto es equivalente a la probabilidad bajo la hipótesis nula de que los datos
%% no sean encontrados en la región de aceptancia, es decir, $\alpha = P(T(\mathcal{D}) \geq k_\alpha|H_0)$

%% En contraste, si uno acepta la hipótesis nula cuando la alternativa es verdadera, es llamado
%% error de tipo II. La probabilidad de cometer este errores la denota $\beta$ y esta dada por
%% $\beta = P(T(\mathcal{D}) < k_\alpha|H_1)$. Se llama \emph{poder del test} a $1-\beta$.

%% Lo que se quiere encontrar es un test estadístico que maximiza el poder del test para un valor
%% fijo de tamaño del test $\alpha$.

La probabilidad de rechazar $H_0$ siendo esta verdadera es denominado tamaño del test y
es,

\begin{equation}
  \alpha = \int_{R} g(t|H_0)\, dt
\end{equation}

lo cual también determina el nivel de significancia como
$(100 - \alpha) \%$. Este error de rechazar $H_0$ cuando es verdadera es llamado
error de tipo I. Por otro lado el error de aceptar $H_0$ cuando es falsa se
llama error de tipo II, y su probabilidad de ocurrencia, $\beta$, depende de la
hipótesis alternativa $H_1$. El poder del test se define como: %%  como la probabilidad de
%% rechazar la hipótesis cuando es falsa:

\begin{equation}
1-\beta = \int_R g(t|H_1)\, dt
\end{equation}

En principio cualquier función de los datos puede ser utilizada como estadístico
de prueba, pero un buen estadístico será aquel para el cual sus distribuciones
para la hipótesis nula y alternativa estén claramente separadas. Para esto se
busca el estadístico de prueba que tenga el mayor poder posible, para un dado
tama\~no.

Para el caso de hipótesis simples, el teorema de Neyman-Pearson afirma que el
estadístico de prueba con mayor poder para un tama\~no $\alpha$ esta dado por:

%% Para el caso de dos hipótesis simples (sin parámetros), el test estadístico con mayor
%% poder esta dado por el \emph{likelihood ratio} $T_\text{NP} = \vec{f}(\mathcal{D}|H_1)/\vec{f}(\mathcal{D}|H_0)$.
%% Este resultado se conoce como lema de Neyman-Pearson.

\begin{equation}
  t(\bm{x}) = \frac{f(\bm{x}|H_1)}{f(\bm{x}|H_0)}
\end{equation}

Desafortunadamente no hay un equivalente al lema de Neyman-Pearson para modelos
con muchos parámetros libres. Sin embargo, hay una generalización natural basada
en el PLR.

Para el caso de un conjunto de datos muy grandes ($N$ grande), la distribución
de las medias de los observables $\bm{x}$ va a seguir una distribución normal
incluso si las cantidades medidas $\bm{x}$ no siguen una distribución normal.
Esto es consecuencia del \emph{teorema central del límite}. En este caso, la pdf
del estadístico de prueba $t$ puede ser fácilmente determinada (ver \cref{sec:aprox}).
En el caso
general, sin embargo, es necesario utilizar simulaciones Monte Carlo para
general lo que se denominan \emph{pseudo-experimentos}. El procedimiento
consiste en generar el conjunto de observables $\bm{x}$ utilizando la pdf
$f(\bm{x}|H)$ y calculando el valor del estadístico de prueba $t(\bm{x})$ para
cada conjunto. Este proceso se repite hasta acumular la suficiente estadística
en la distribución de $g(t|H)$.

El nivel de acuerdo entre los datos observados y una hipótesis $H$ es
cuantificado calculando el \emph{\pvalue}, es decir, la probabilidad, bajo la
suposición de que $H$ es cierta, de observar datos de igual o menor
compatibilidad con la predicción de $H$, respecto a los datos observados.

\begin{equation}
  p_H = P(t>t_\text{obs}|H) = \int_{t_\text{obs}}^{\infty} g(t|H) \, dt
\end{equation}
%
donde $t_\text{obs}$ es el valor del estadístico de prueba obtenido con los
datos observados.

De esta forma, un {\pvalue} grande denota que la evidencia en contra de $H_0$ es
débil y un {\pvalue} chico denota que los datos contienen mucha evidencia en
contra de $H_0$.
%% En este sentido de p-valores, se puede no hablar de pruebas de hip´otesis, sino de
%% pruebas de significancia, donde la cuantificaci´on del concepto abstracto de significancia
%% es el p-valor
Se dice que la hipótesis es excluida si el {\pvalue} esta por debajo de un valor
especifico dado por el tama\~no del test $\alpha$, donde $\alpha \in [0,1]$.

En física de partículas es usual convertir el {\pvalue} en la signifícancia
equivalente, $Z$, definida como,
\begin{equation}
  Z = \Phi^{-1}(1-p)
\end{equation}
%
donde $\Phi^{-1}$ es el cuantil (la función inversa de la distribución
acumulativa) de la distribución gaussiana.


%% Los modelos de probabilidad pueden construirse para describir simultáneamente varios
%% canales, es decir, varias regiones disjuntas de datos asociadas a un criterio de selección.
%% Si usamos $e$ como el índice sobre eventos y $c$ el índice sobre canales, los datos
%% van a ser una colección de datos: $\mathcal{D}_\text{sim} = {\mathcal{D}_1, \ldots, \mathcal{D}_{c_max}}$.
%% El punto clave ahora, es que va a haber múltiples términos de Poisson.

%% \begin{equation}
%%   \vec{f}_\text{sim} (\mathcal{D}_\text{sim}|\alpha) = \prod_{c \in \text{canales}} \left[ \Pois(n_c|\nu{(\alpha)}) \prod_{e=1}^{n_c} f(x_{c,e}|\alpha) \right]
%% \end{equation}


\section{Descubrimiento}

Para la búsqueda de nueva física es común definir como parámetro de interés a la
intensidad de la señal como el cociente entre la sección eficaz de nueva física
y la sección eficaz del SM, $\mu = \sigma/\sigma_\text{nominal}$.
De esta forma la hipótesis de sólo-fondo corresponde a $\mu = 0$ , y
la hipótesis de señal+fondo a $\mu = 1$.

%% Si $\hat{\mu}$ y $\hat{\btheta}$ son los valores que maximizan $L(\mu,\btheta)$ o minimizan
%% $- \ln L(\mu, \btheta)$ y $\bdtheta$ es el valor que maximiza $L$ para un valor fijo de $\mu$
%% (the profile value of \btheta), el cociente de likelihood es,

Aunque es cierto que un valor de $\hat{\mu}$ mucho menor a cero representa
evidencia contra el modelo de sólo-fondo, este tipo de discrepancia no muestran
que los datos contengan eventos de señal. Es por este motivo que sólo se
considera que los datos no tienen un buen acuerdo con la hipótesis de sólo-fondo
cuando $\hat{\mu}$ es mayor a cero. En otros experimentos, como los de
oscilaciones de neutrinos por ejemplo, la hipótesis de señal puede predecir un
número mayor o menor de eventos con respecto a la hipótesis de no oscilaciones.

Entonces para este  caso de $\mu \geq 0$ conviene definir,

\begin{equation}
  \tilde{\lambda}(\mu) =
  \begin{cases}
    \frac{L(\mu, \doublehat{\btheta})}{L(\hat{\mu}, \hat{\btheta})} & \hat{\mu} \geq 0 \\
    \frac{L(\mu, \doublehat{\btheta})}{L(0, \hat{\btheta}(0))} & \hat{\mu} < 0
  \end{cases}
\end{equation}

Acá $\doublehat{\btheta}(0)$ y $\doublehat{\btheta}(\mu)$ se refieren a los MLE
de {\btheta} dados los parámetros de intensidad de señal parámetro de 0 o $\mu$
respectivamente. El correspondiente estadístico de prueba puede obtenerse como,

\begin{equation}
  \tilde{t}_\mu = -2 \ln \tilde{\lambda}(\mu) %% \begin{cases} %% -2 \ln  \frac{L(\mu, \hat{\hat{\bm{\theta}}})}{L(0, \hat{\bm{\theta}}(0))} & %%
  %%-\hat{\mu} < 0 \\ %%2 \ln \frac{L(\mu, \hat{\hat{\bm{\theta}}})}{L(\hat{\mu}, %%     -\hat{\bm{\theta}})} & \hat{\mu} \geq 0 %% \end{cases}
\end{equation}

Un caso de especial importancia del estadístico $t_\mu$ es cuando $\mu=0$ en un
modelo en el que asumimos $\mu \geq 0$. Rechazar la hipótesis de $\mu=0$ es lo
que llamamos \emph{descubrimiento} de una nueva señal. Para este caso se define
$\tilde{q}_0=\tilde{t}_0$ como,

\begin{equation}
  \tilde{q}_0 =
  \begin{cases}
    -2 \ln \tilde{\lambda}(0) & \hat{\mu} > 0 \\
    0 & \hat{\mu} \leq 0
  \end{cases}
\end{equation}

Si los datos fluctúan de tal manera que haya menos eventos que los predichos por
el fondo, entonces $\hat{\mu} = 0$ y $q_0=0$. A medida que el número de
eventos crece por encima del número de eventos de fondo esperado (mayor
$\hat{\mu}$) el valor de $q_0$ es mayor, lo que corresponde a un incremento en
el nivel de incompatibilidad con la hipótesis de sólo-fondo. Para cuantificar el
nivel de desacuerdo entre datos y la hipótesis de $\mu=0$ usando el valor
observado de $q_0$ se calcula el {\pvalue} como,

\begin{equation}
  p_0 = \int_{q_{0,\text{obs}}}^{\infty} f(q_0|\mu=0) \, dq_0
  \label{eq:p0}
\end{equation}

En el caso de que $p_0 \leq \epsilon$ donde $\epsilon$ es un tamaño del test
fijado anteriormente, se dice que hay un descubrimiento. En general en física de
altas energías suele utilizarse $\epsilon = 2.87 \times 10^{-7}$, el cual
corresponde a una significancia equivalente $Z=5\sigma$.

Es importante notar que el hecho de rechazar la hipótesis de sólo-fondo en un
sentido estadístico es sólo parte de descubrir un fenómeno nuevo.
Para confirmar la presencia de este nuevo fenómeno es necesario estudiar
el acuerdo de este para describir los datos observados.


\section{Límites de Exclusión}

Por el contrario, si $p_0> \epsilon$ no se puede rechazar $H_0$. Esto no
significa que todos los valores de $\mu$ bajo $H_1$ estén excluidos.
\hl{En particular, hay valores de $\mu$ a los que el analisis no es sensible
y valores que los datos observados no permite excluir.}
Lo que hay
que hay que poner a prueba ahora es $H_1[\mu_0]: \mu = \mu_0$ contra $H_0[\mu_0]: \mu < \mu_0$.
Con motivo de realizar esta prueba se define $\tilde{q}_\mu$,

\begin{equation}
  \tilde{q}_\mu =
  \begin{cases}
    -2 \ln \tilde{\lambda}(\mu) & \hat{\mu} \leq \mu \\
    0 & \hat{\mu} > \mu
  \end{cases} \label{eq:qmu}
\end{equation}

%% Conviene notar que para establecer un límite superior, una fluctuación hacia
%% arriba de los datos no representa una mayor incompatibilidad de la hipótesis
%% $\mu$.
La razón para poner $q_\mu = 0$ para $\hat{\mu} > \mu$ es que cuando se
establece un límite superior, el hecho de que $\hat{\mu} > \mu$ representa menos
compatibilidad con $\mu$ que los datos obtenidos, y por lo tanto no se considera
parte de la región de rechazo de la constrastación.

También es importante notar, que $q_0$ (utilizado como estadístico de prueba para
descubrimiento) no es simplemente un caso especial de la
\cref{eq:qmu}, sino que tiene una definición diferente. Es decir, $q_0$ es cero
si los datos fluctúan hacia abajo ($\hat{\mu}<0$), pero $q_\mu$ es cero si los
datos fluctúan hacia arriba ($\hat{\mu}>\mu$).

%%Para los datos observados se tiene $\tilde{q}_\mu^\text{obs}$.
%% Para generar la
%% distribución de $\tilde{q}_\mu$ se pueden generar pseudo-experimentos con Monte
%% Carlo $\to$ $f(\tilde{q}_\mu|\mu, \btheta)$.

El {\pvalue} para una observación bajo una hipótesis $(\mu,\btheta)$ es la
probabilidad de obtener un resultado igual o mas extremo que los obtenidos dado
H.

\begin{equation}
  p_{(\mu,\btheta)} = \int_{\tilde{q}_{\mu,\text{obs}}}^{\infty}
  f(\tilde{q}_\mu|\mu,\btheta) \, d\tilde{q}_\mu
\end{equation}

Este {\pvalue} presenta como dificultad que no no sólo depende del parámetro de interés,
sino también de $\btheta$. La hipótesis no puede ser rechazada a menos que
el {\pvalue} sea suficientemente chico para todos los valores de $\btheta$. De forma
equivalente se utiliza el supremo del {\pvalue} para decidir si la hipótesis de $\mu = \mu_0$
es aceptada o rechazada.

\begin{equation}
  p_\mu^\text{sup} = \sup_\theta p_{(\mu,\btheta)}
\end{equation}

La mayor razón para usar PLR como test estadístico es que en el límite de muchos
eventos la distribución del PLR $\lambda(\mu=\mu_\text{0})$ es independiente
de los valores de los parámetros nuisance $p_\mu^\text{sup} = p_{(\mu,\btheta)}
\forall \theta$. Esto es una consecuencia del Teorema de Wilk.
Elegir $\btheta^\text{sup} = \doublehat{\btheta}(\mu)$, es decir, el valor para el
cual $p_{(\mu,\btheta)} = p_\mu^\text{sup}$ es un buen valor estimado de
$\btheta^\text{sup}$.

Para cuantificar la consistencia de los datos observados con la hipótesis de
intensidad de se\~nal $\mu$ se calcula el {\pvalue}

\begin{equation}
  p_\mu = \int_{\tilde{q}_{\mu,\text{obs}}}^{\infty} f(\tilde{q}_\mu|\mu,\doublehat{\btheta}(\mu, \text{obs})) \, d\tilde{q}_\mu \equiv \clsb
  \label{eq:pmu}
\end{equation}
%
donde valores chicos de $p_\mu$ indican baja compatibilidad con la hipótesis
de señal+fondo.

El intervalo de confianza o límite superior con un nivel de
confianza del 95\% se obtiene resolviendo la siguiente ecuación:

\begin{equation}
  p_{\mu_\text{up}} = 0.05
\end{equation}

Pero el límite superior calculada de esta forma tiene un problema. De acuerdo
 a este se dice que una señal esta excluida a 95\% CL, si ${\clsb} \leq 0.05$.
Si se considera el caso de $\mu=0$, se espera que por construcción
el {\clsb} sea menor o igual que 0.05 con una probabilidad de 5\%. Esto significa que
en el 5\% de los análisis estarían excluyendo modelos con cero señal.
Otro problema del {\clsb} es que para dos experimentos con el mismo
número chico de eventos de señal esperado pero con un numero de eventos de fondo distinto, el
experimento con mayor fondo va a imponer mejores límites.

Con motivo de solucionar estos inconvenientes se introduce el método de {\cls}.
%% Se define el {\clb},

%% Los intervalos de confianza frecuentistas cubren e
%% Un limite superior con 95\% de nivel de confianza cubre al valor verdadero con una probabilidad de
%% 95\%. Eso sinifica que un 5\% de las veces no lo cubre. Esto significa, que si no hay senal, el 5\% de las veces
%% se esta excluyendo cualquier valor positivo de XS.

\begin{equation}
  \cls = \frac{p_\mu}{1-p_b}  \equiv \frac{\clsb}{\clb}
\end{equation}
%
donde $p_b$ es el valoro del mismo test bajo la hipótesis de sólo-fondo,

\begin{equation}
  1 - p_b = \int_{\tilde{q}_\mu^\text{obs}}^{\infty}
  f(\tilde{q}_\mu|0,\doublehat{\btheta}(\mu=0)) \, d\tilde{q}_\mu \equiv \clb
\end{equation}

El límite superior {\cls} en $\mu$, $\mu_\text{up}$ se obtiene resolviendo
$p_{\mu_\text{up}} = 0.05$. Se rechazan los valores de $\mu$ si $\mu <
\mu_\text{up}$ con un nivel de confianza de 95\%.

Para una observación cercana al numero de eventos esperado de sólo-fondo ($\clb
\sim 0.05$) el {\cls} da un valor del orden de dos veces el obtenido utilizando
el {\clsb}.
%% Entonces, el método {\cls} evita no sólo el problema descripto anteriormente, sino también
%% la propiedad indeseable del {\clsb} que para dos


\section{Aproximación asintótica del PLR}\label{sec:aprox}

Para poder calcular el {\pvalue} de una hipótesis utilizando las ecuaciones
\eqref{eq:p0} y \eqref{eq:pmu} se necesita conocer las distribuciones muestrales
del estadístico de prueba, $f(t)$.

%% Para un test de un unico parametro $\mu$ que representa la intensidad de senal, que
%% puede ser cero (descubrimiento) o no nulo (para limite superior), y usando el resultado
%% de Wald\cire{WaldTheo} vale,

%% \begin{equation}
%%   -2 \log \lambda(\mu) = \frac{(\mu - \hat{\mu})^2}{\sigma^2} + \mathcal{O}(1/\sqrt{N})
%% \end{equation}
%% %
%% donde $\hat{\mu}$ sigue una distribucion normal con media $\mu'$ y desviacion estandar $\sigma$,
%% y $N$ representa el tamano de los datos.

%% %% y si los datos
%% %% estan distribuidos de acuerdo a un parametro $\mu'$. La funcion deseada $f
En el límite asintótico, es decir, de una gran muestra de datos ($N\to\infty$)\cite{AsymAprox}, y
utilizando el teorema de Wilks\cite{WilksTheo} y Wald\cite{WaldTheo} es posible
escribir la distribución de $q_0$ completa como,

\begin{equation}
  f(q_0|\mu') = \left( 1 - \Phi\left(\frac{\mu'}{\sigma}\right)\right)
  \delta(q_0) + \frac{1}{2}\frac{1}{\sqrt{2\pi}}\frac{1}{\sqrt{q_0}} \exp \left[
    -\frac{1}{2} \left( \sqrt{q_0} - \frac{\mu'}{\sigma} \right)\right]
\end{equation}

Para el caso especial de $\mu' = 0$ la distribución se reduce a:

\begin{equation}
  f(q_0|0) = \frac{1}{2} \delta(q_0) +
  \frac{1}{2}\frac{1}{\sqrt{2\pi}}\frac{1}{\sqrt{q_0}} e^{-q_0/2}
\end{equation}

En este límite, $f(q_0|0)$ es independiente de los parámetros
nuisance, aunque $f(q_0|\mu')$ depende de los parámetros nuisance a través de
$\sigma$.

De la pdf, la distribución acumulada de $q_0$ es,

\begin{equation}
  F(q_0|\mu') = \Phi \left( \sqrt{q_0} - \frac{\mu'}{\sigma} \right)
\end{equation}

Para el caso especial $\mu' = 0$ es $F(q_0|0) = \Phi(\sqrt{q_0})$ y el valor-$p$
de la hipótesis $\mu=0$ es

\begin{equation}
  p_0 = 1 - F(q_0|0)
\end{equation}

y la significancia de descubrimiento $Z$ es simplemente,

\begin{equation}
  Z_0 = \Phi^{-1} (1-p_0) = \sqrt{q_0}
\end{equation}

Para el caso de establecer un límite superior se necesita la pdf de $q_\mu$. En el
límite asintótico y utilizando la misma aproximación que en el caso anterior puede
mostrarse que la distribución de $q_\mu$ es,

\begin{equation}
  f(q_\mu|\mu') = \Phi\left(\frac{\mu'-\mu}{\sigma}\right) \delta(q_\mu) +
  \frac{1}{2}\frac{1}{\sqrt{2\pi}}\frac{1}{\sqrt{q_0}} \exp \left[ -\frac{1}{2}
    \left( \sqrt{q_\mu} - \frac{\mu'-\mu}{\sigma} \right)^2\right]
\end{equation}
%
y el correspóndete {\pvalue} y significancia están dados por

\begin{equation}
  p_\mu = 1 - \Phi(\sqrt{q_\mu})
\end{equation}

\begin{equation}
  Z_\mu = \Phi^{-1}(1-p_\mu) = \sqrt{q_\mu}
\end{equation}

Estas aproximaciones permiten conocer las distribuciones muestrales y calcular
{\pvalue}s y significancias en el caso de un gran número de datos, de una forma
simple y computacionalmente menos costosa que si se tuvieran que generar un gran
número de pseudo-experimentos utilizando métodos Monte Carlo. A pesar de que las
aproximaciones son formalmente validas en ese limite, las comparaciones con
Monte Carlo, muestran que el uso de las mismas son razonablemente precisas para
muestras de datos mucho mas chicas, permitiendo su uso en la mayoría de los
análisis. Para muestras de datos muy pequeñas, o en casos donde la precisión es
importante, siempre pueden validarse estas aproximaciones utilizando la
generación Monte Carlo.


\section{Significancia esperada} %%Sensibilidad de descrubrimiento para un experimento de conteo}

%% When planning the experiment, we want to quantify how sensitive
%% we are to a potential discovery, e.g., by given median significance
%% assuming some nonzero strength parameter mu'.
%% So for p-value, need f(q0 |0), for sensitivity, will need f(q0 | mu'),

En física de partículas la cantidad $s/\sqrt{b}$ ha sido siempre utilizada como
una medida de la significancia esperada de descubrimiento. La explicación detrás
de esta formula es que una cantidad $n$ que sigue una distribución de Poisson
con una media grande $s+b$ puede ser aproximada por una variable $x$
distribuidas según una gaussiana con media $s+b$ y desviación estándar
$\sqrt{s+b}$. En este caso el valor-$p$ de la hipótesis de sólo-fondo dada una
observación $x$ esta dado por,

\begin{equation}
  p = 1 - \Phi \left( \frac{x-\mu}{\sigma} \right) = 1 - \Phi \left(
  \frac{x-b}{b} \right)
\end{equation}
%
donde $\mu=b$ y $\sigma = \sqrt{b}$ se refieren a la media y la desviación
estándar de $x$ asumiendo que $s=0$. Traduciendo este {\pvalue} a significancia,

\begin{equation}
  Z = \frac{x-b}{b}
\end{equation}

La significancia esperada, a diferencia de la observada, se calcula desde la mediana
de la hipótesis alternativa. Entonces como la mediana de la hipótesis de señal+fondo,
en este caso igual a la media, es $s+b$,

\begin{equation}
  Z_\text{exp} = \frac{s}{\sqrt{b}}
  \label{eq:Zsimple}
\end{equation}
%
que es la ecuación conocida. %% Y para generalizar esta ecuación para el caso de que el
%% numero de eventos de fondo tenga una incerteza sistemática

%% utilizando la aproximación
%% asintotica de la seccion anterior,
De forma general, para el caso un numero de eventos de fondo $b$ conocido con
una incerteza despreciable, se puede escribir la función likelihood como,

\begin{equation}
  L(s) = \frac{(s+b)^n}{n!} e^{-(s+b)}
\end{equation}
%
y utilizando la aproximación asintótica, la significancia de descubrimiento
puede ser aproximada por $Z=\sqrt{q_0}$, lo que da como resultado,

%% \begin{equation}
%%   Z = \sqrt{2\left( n \ln \frac{n}{b} +b -n \right)}
%%   \label{eq:Z}
%% \end{equation}
%
%% para $n>b$ y $Z=0$ para $n<b$. También puede aproximarse la significancia esperada
%% reemplazando los datos por el conjunto de datos de Asimov. Substituyendo $s+b$
%% por $n$ en la {\eq} \eqref{eq:Z}, la aproximaxion de Asimov para la
%% significancia esperada $Z_A$ es,

\begin{equation}
  Z_A = \sqrt{2\left( (s+b) \ln \left( 1 + \frac{s}{b}\right) - s \right)}
  \label{eq:Z}
\end{equation}

Si expandimos el logaritmo en la ecuación anterior en $s/b$ tenemos $Z_A =
s/\sqrt{b} + \mathcal{O}(s/b)$ que es la expresión de la {\eq}
\eqref{eq:Zsimple} y es valida sólo en el límite $s \ll b$.

Si el número de eventos esperado de fondo $b$ no es conocido, uno debe incluirlo
como un parámetro nuisance en la función likelihood. Pero como $b$ puede
ajustarse para cualquier número de eventos, es necesario introducir información
adicional para restringir $b$. En general se suele hacer mediante una medida
auxiliar, mirando el número de eventos observados $m$ en una región de control
donde se asume que la señal esta ausente, y considerando que $m$ sigue
una distribución de Poisson con media $\tau b$, donde $\tau$ es un factor de
extrapolación.

La función likelihood total es el producto de las dos distribuciones de Poisson
correspondientes a cada región:

\begin{equation}
  L(\mu, \btheta) = \Pois (n;s+b) \Pois(m;\tau b)
\end{equation}

Utilizando la aproximación $Z = \sqrt{q_0}$, valida en el límite de una gran
muestra y teniendo en cuenta que los valores esperados son $s+b$ y $\tau b$ para
obtener la significancia esperada, tenemos:

\begin{equation}
  Z_A = \left[ 2 \left( (s+b) \ln \left[ \frac{s+(1+\tau)b}{(1+\tau)(s+b)}
      \right] + \tau b \ln \left[ 1 + \frac{s}{(1+\tau)b} \right] \right)
    \right]^{1/2}
  \label{eq:Za1}
\end{equation}

Es útil expresar la \cref{eq:Za1} en términos de la incerteza que uno
quiere atribuirle al fondo basados en la medida de control $m$. El estimador
para $b$ esta dado por $\hat{b} = m/\tau$, y como la varianza de $m$ es igual a
su media $\tau b$, la varianza de $\hat{b}$ es $V[\hat{b}] = \sigma_b^2 =
b/\tau$. Y usando esto para eliminar $\tau$ de la \cref{eq:Za1}
obtenemos:

\begin{equation}
  Z_A = \left[ 2 \left( (s+b) \ln \left[
      \frac{(s+b)(b+\sigma_b^2)}{b^2+(s+b)\sigma_b^2} \right] -
    \frac{b^2}{\sigma_b^2} \ln \left[ 1 + \frac{\sigma_b^2 s}{b(b+\sigma_b^2)}
      \right] \right) \right]^{1/2}
  \label{eq:Za}
\end{equation}
%
y expandiendo en potencias de $s/b$ y $\sigma_b^2/b$ obtenemos,

\begin{equation}
  Z_A = \frac{s}{\sqrt{b+\sigma_b^2}} \left( 1 + \mathcal{O}(s/b) + \mathcal{O}(\sigma_b^2/b) \right)
\end{equation}
%
que es la ecuación conocida y es valida cuando $s\ll b$ y $\sigma_b^2 \ll b$.




%% \subsection{Psuedo-experimentos}

%% The role of intervals in Search Procedures

%% Exclusion A signal hypothesis can be excluded if the compatibility with the s C b
%% hypothesis is ‘small’. Several limit-setting methods exist and are a source of in-
%% tense discussions among physicists, to say the least (see also Section 4.6). Although
%% it might seem natural to define a signal as excluded at 95% confidence level if
%% CL sCb < 5%, there are some undesirable consequences associated with this choice.
%% Near the sensitivity limit, where the test statistic distribution for the b-only and sCb
%% hypotheses are not well separated (either because the signal is small or the analysis
%% is not powerful enough to separate signal and background), a downward fluctua-
%% tion in the data with respect to the b-only expectation will result in the exclusion
%% of a signal while the analysis has no real sensitivity. One of the common solutions

%% experiments invoke to address this issue is to correct for a downward fluctuation
%% by using the so-called CL s method [6], where a signal is called ‘excluded’ at 95%
%% confidence level if CL s < 0.05, where CL s


%% Para ilustrar el uso del likelihood ratio, consideremos un experimento en el cual por cada evento,
%% se miden los valores de ciertas variables cinematicas, entonces los datos pueden ser representados
%% por uno o mas histogramas.

%% Supongamos el histograma $\vec{n} = (n_1, n_2, \ldots, n_n)$. El valor esperado para $n_i$ puede
%% escribirse $E[n_i] = \mu s_i + b_i$, donde el valor medio de entradas del bin $i$ de se\~nal y fondo
%% son:

%% El parametro $\mu$ determina la intensidad de la nueva se\~nal, donde $\mu=0$ corresponde a la
%% hipotesis de solo-fondo, y $\mu=1$ es la hipotesis de se\~nal.
%% Las funciones $f_s$ y $f_b$ son las \pdf\ de la variable x para los eventos de se\~nal y fondo, y
%% $\theta_s$ y $\theta_b$ representan parametros que caracterizan la forma de las pdfs. Las
%% cantidades $s_\text{tot}$ y $b_\text{tot}$ son el valor medio total de se\~nal y fondo, y las
%% integrales en \ref{} y \ref{} representan la probabilidad de que un evento sea encontrado en el
%% bin $i$. En lo que sigue $\bm{\theta} = (\bm{\theta}_s, \bm{\theta}_b, b_\text{tot})$

%% Además del histograma $\bm{n}$, se utilizan otras medidas adicionales que ayuden a restringir
%% los parametros nuisance. Por ejemplo, se pueden elegir regiones de control donde uno espera
%% mayormente fondo, y construit un histograma $\bm{m}$. Los valores esperados de $m_i$ pueden
%% escribirse como $E[m_i] = u_i(\bm{\theta})$, donde los $u_i$ son cantidades calculadas a partir
%% de $\bm{\theta}$.

%% \itodo{
%%   It is often said that the language of science is mathematics. It could well be said that the language of experimental science is statistics.
%%   It is through statistical concepts that we quatify
%%   the correspondence between theoretical predicticions and experimental observations. While the statistical
%%   analysis of the dta is often treated as a final subsidiary step to an experimental physcis
%%   result, a more direct approach would be quite the opposite. In fact, thinking through the
%%   requirements for a robust statistical statement is an excellent way to organize an analysis
%%   strategy.
%%   }





%% \subsection{Probabilidad}

%% La definición matemática de probabilidad

%% Consideremos A un evento. Luego la probabilidad $P(A)$ es un numero que obedece los tres
%% axiomas de Kolmogorov\cite{Kolmogorov}.

%% \begin{align}
%%   &P(A) \geq 0, \\
%%   &P(S) = 1, \\
%%   &A \cap B = \phi \Rightarrow P(A \cup B) = P(A) + P(B)
%% \end{align}
%% %
%% donde $S$ es el conjunto de A.

%% La definición frecuentista de probabilidad esta dada por:

%% \begin{equation}
%%   P(A) = \lim_{n\to\infty} \frac{\text{resultado es} A}{n}
%% \end{equation}


%% \begin{equation}
%%   P(A|B) = \frac{P(B|A) P(A)}{P(B)}
%% \end{equation}
%% %
%% donde $P(B|A)$ es la probabilidad de B dado A, $P(A)$ es la probabilidad \emph{a priori} de A,
%% y ...
